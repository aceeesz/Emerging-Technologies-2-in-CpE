{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aceeesz/Emerging-Technologies-2-in-CpE/blob/main/Ass_5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment 5.2: Build and Apply Multilayer Perceptron**\n",
        "\n",
        "\n",
        "**Group 15 - BSCPE32S1**\n",
        "\n",
        "\n",
        "- Efa, Christian Ed\n",
        "- Sierra, Charls Ryan"
      ],
      "metadata": {
        "id": "WPaM3ZNyQt1B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enw8SM2hVPwV"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Importing data\n",
        "data = pd.read_csv('/content/data.csv')\n",
        "del data['Unnamed: 32']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 2:].values\n",
        "y = data.iloc[:, 1].values\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "y = labelencoder_X_1.fit_transform(y)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
        "\n",
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "oEuUyHgxVWIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sequential model\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding an input layer with 30 dimensions (assuming 30 input features)\n",
        "# and 16 hidden units, with uniform initialization and ReLU activation\n",
        "classifier.add(Dense(units=16, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
        "\n",
        "# Adding dropout to prevent overfitting\n",
        "classifier.add(Dropout(rate=0.1))\n",
        "\n",
        "# Adding a hidden layer with 16 hidden units, with uniform initialization and ReLU activation\n",
        "classifier.add(Dense(units=16, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# Adding dropout to prevent overfitting\n",
        "classifier.add(Dropout(rate=0.1))\n",
        "\n",
        "# Adding an output layer with a single unit (assuming binary classification)\n",
        "# and sigmoid activation\n",
        "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\n",
        "# Compiling the model using binary cross-entropy loss and Adam optimizer\n",
        "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model with the training data\n",
        "# classifier.fit(x_treinamento, y_treinamento, epochs=100, batch_size=10)"
      ],
      "metadata": {
        "id": "uUt-IhowVYlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1ff06c-8701-45ba-ec0f-e35cc8ace091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8txxMNgSqURO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras"
      ],
      "metadata": {
        "id": "mhN1nu4pmMuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e2883b-c510-4257-e87f-db75121defa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.10.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the ANN to the Training set\n",
        "classifier.fit(X_train, y_train, batch_size=100, epochs=150)\n",
        "# Long scroll ahead but worth\n",
        "# The batch size and number of epochs have been set using trial and error."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWGmFo9_W5-G",
        "outputId": "5053c3d1-48ff-447e-c1e5-1885b8143287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5349 - loss: 0.6929\n",
            "Epoch 2/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6516 - loss: 0.6913 \n",
            "Epoch 3/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.6893 \n",
            "Epoch 4/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.6856 \n",
            "Epoch 5/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.6792 \n",
            "Epoch 6/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.6686 \n",
            "Epoch 7/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.6530 \n",
            "Epoch 8/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9350 - loss: 0.6292\n",
            "Epoch 9/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9329 - loss: 0.6021 \n",
            "Epoch 10/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.5628 \n",
            "Epoch 11/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9486 - loss: 0.5232 \n",
            "Epoch 12/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9437 - loss: 0.4766  \n",
            "Epoch 13/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.4388 \n",
            "Epoch 14/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.3862 \n",
            "Epoch 15/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.3501 \n",
            "Epoch 16/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.3180 \n",
            "Epoch 17/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.2811 \n",
            "Epoch 18/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9640 - loss: 0.2626 \n",
            "Epoch 19/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.2283 \n",
            "Epoch 20/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.2182 \n",
            "Epoch 21/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1960 \n",
            "Epoch 22/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1798 \n",
            "Epoch 23/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1689 \n",
            "Epoch 24/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.1429 \n",
            "Epoch 25/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.1423 \n",
            "Epoch 26/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.1253 \n",
            "Epoch 27/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.1325 \n",
            "Epoch 28/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.1185 \n",
            "Epoch 29/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.1141 \n",
            "Epoch 30/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0968 \n",
            "Epoch 31/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9759 - loss: 0.0948 \n",
            "Epoch 32/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0992 \n",
            "Epoch 33/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0935 \n",
            "Epoch 34/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0837 \n",
            "Epoch 35/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.0921 \n",
            "Epoch 36/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0866  \n",
            "Epoch 37/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0877 \n",
            "Epoch 38/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9810 - loss: 0.0898  \n",
            "Epoch 39/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9776 - loss: 0.0970  \n",
            "Epoch 40/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0804 \n",
            "Epoch 41/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0802 \n",
            "Epoch 42/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9788 - loss: 0.0784  \n",
            "Epoch 43/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.0674 \n",
            "Epoch 44/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0640 \n",
            "Epoch 45/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0843 \n",
            "Epoch 46/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0840 \n",
            "Epoch 47/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0761 \n",
            "Epoch 48/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0769  \n",
            "Epoch 49/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0564 \n",
            "Epoch 50/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0721 \n",
            "Epoch 51/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0829 \n",
            "Epoch 52/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0639  \n",
            "Epoch 53/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0705 \n",
            "Epoch 54/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.0485  \n",
            "Epoch 55/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0761 \n",
            "Epoch 56/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9850 - loss: 0.0684 \n",
            "Epoch 57/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0632  \n",
            "Epoch 58/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0583 \n",
            "Epoch 59/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0719 \n",
            "Epoch 60/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0598 \n",
            "Epoch 61/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0581 \n",
            "Epoch 62/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9810 - loss: 0.0637  \n",
            "Epoch 63/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9872 - loss: 0.0572  \n",
            "Epoch 64/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0743  \n",
            "Epoch 65/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0707  \n",
            "Epoch 66/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.0761  \n",
            "Epoch 67/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0601  \n",
            "Epoch 68/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9828 - loss: 0.0625 \n",
            "Epoch 69/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0714 \n",
            "Epoch 70/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0675  \n",
            "Epoch 71/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0634 \n",
            "Epoch 72/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0481 \n",
            "Epoch 73/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0545  \n",
            "Epoch 74/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0550 \n",
            "Epoch 75/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.0610  \n",
            "Epoch 76/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0569 \n",
            "Epoch 77/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0752  \n",
            "Epoch 78/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9811 - loss: 0.0676  \n",
            "Epoch 79/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0434 \n",
            "Epoch 80/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0672  \n",
            "Epoch 81/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0473  \n",
            "Epoch 82/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0566 \n",
            "Epoch 83/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0519 \n",
            "Epoch 84/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0531  \n",
            "Epoch 85/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0580 \n",
            "Epoch 86/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0508 \n",
            "Epoch 87/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.0495 \n",
            "Epoch 88/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.0522 \n",
            "Epoch 89/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0710\n",
            "Epoch 90/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9850 - loss: 0.0627 \n",
            "Epoch 91/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0562  \n",
            "Epoch 92/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0549 \n",
            "Epoch 93/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.0458  \n",
            "Epoch 94/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0666  \n",
            "Epoch 95/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0500  \n",
            "Epoch 96/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0511  \n",
            "Epoch 97/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0471 \n",
            "Epoch 98/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.0567 \n",
            "Epoch 99/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0402 \n",
            "Epoch 100/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0438  \n",
            "Epoch 101/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0393  \n",
            "Epoch 102/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0553 \n",
            "Epoch 103/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0515  \n",
            "Epoch 104/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0476 \n",
            "Epoch 105/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0511  \n",
            "Epoch 106/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0550  \n",
            "Epoch 107/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0642  \n",
            "Epoch 108/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0594  \n",
            "Epoch 109/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0585 \n",
            "Epoch 110/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0591  \n",
            "Epoch 111/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0377 \n",
            "Epoch 112/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0499 \n",
            "Epoch 113/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0492  \n",
            "Epoch 114/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0467 \n",
            "Epoch 115/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0477  \n",
            "Epoch 116/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0448 \n",
            "Epoch 117/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0407  \n",
            "Epoch 118/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0585  \n",
            "Epoch 119/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0626 \n",
            "Epoch 120/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0514 \n",
            "Epoch 121/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0551  \n",
            "Epoch 122/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.0420 \n",
            "Epoch 123/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0434  \n",
            "Epoch 124/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0388 \n",
            "Epoch 125/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0574  \n",
            "Epoch 126/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9883 - loss: 0.0490  \n",
            "Epoch 127/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0580  \n",
            "Epoch 128/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9911 - loss: 0.0496\n",
            "Epoch 129/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0527  \n",
            "Epoch 130/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9845 - loss: 0.0453  \n",
            "Epoch 131/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0385  \n",
            "Epoch 132/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.0478  \n",
            "Epoch 133/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0497  \n",
            "Epoch 134/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9905 - loss: 0.0323\n",
            "Epoch 135/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0330  \n",
            "Epoch 136/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0520 \n",
            "Epoch 137/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0346  \n",
            "Epoch 138/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0441  \n",
            "Epoch 139/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0338  \n",
            "Epoch 140/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0359  \n",
            "Epoch 141/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0319 \n",
            "Epoch 142/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0400 \n",
            "Epoch 143/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0378 \n",
            "Epoch 144/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0574  \n",
            "Epoch 145/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0587  \n",
            "Epoch 146/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0429  \n",
            "Epoch 147/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0345 \n",
            "Epoch 148/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0440  \n",
            "Epoch 149/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0320 \n",
            "Epoch 150/150\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9939 - loss: 0.0311  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a8274c3e200>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrZ_jhSvW9RL",
        "outputId": "35ab7cf7-aa1c-47ec-dc95-ae0f5afd06e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prints the accuracy of the classification model. It calculates the accuracy by dividing the sum of true positives\n",
        "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/57)*100))\n",
        "\n",
        "#creates a heatmap visualization of the confusion matrix using the Seaborn library\n",
        "sns.heatmap(cm,annot=True)\n",
        "#saves the generated heatmap as an image file named 'h.png' in the current directory.\n",
        "plt.savefig('h.png')"
      ],
      "metadata": {
        "id": "J-ZpJre0XEpP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "6893f69a-0648-40e0-efea-bae453ecbdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our accuracy is 98.24561403508771%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Choose any dataset**\n",
        "- We have chosen about Breast Cancer Wisconsin (Diagnostic)\n",
        "\n",
        "**Explain the problem you are trying to solve**\n",
        "- Data Set Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei\n",
        "\n",
        "\n",
        "**Create your own model**\n",
        "- We Have created a model with a 98% accuracy using Sigmoid function used when dealing with classfication problems with 2 types of results. Optimizer is chosen as adam for gradient descent.\n",
        "\n",
        "\n",
        "**Evaluate the accuracy of your model**\n",
        "-   the batch size and number of epochs, trial and error is a common approach that we have took in order to gain a high accuracy outcome such as 98.24561403508771%"
      ],
      "metadata": {
        "id": "0eECFirn_ItY"
      }
    }
  ]
}